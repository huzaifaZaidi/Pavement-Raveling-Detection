{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42bb5276",
   "metadata": {},
   "source": [
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21fbb132",
   "metadata": {},
   "source": [
  
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b740b0",
   "metadata": {},
   "source": [
    "SOLUTION: ARTIFICIAL NEURAL NETWORK WITH ONE HIDDEN LAYER:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "32b09dcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_9004\\2242147268.py:32: RuntimeWarning: divide by zero encountered in log2\n",
      "  entropy = -np.sum(np.log2(image / 256) * (image / 256), axis=(0, 1))\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_9004\\2242147268.py:32: RuntimeWarning: invalid value encountered in multiply\n",
      "  entropy = -np.sum(np.log2(image / 256) * (image / 256), axis=(0, 1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/350\n",
      "22/22 [==============================] - 1s 2ms/step - loss: 0.5750 - accuracy: 0.7086\n",
      "Epoch 2/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4572 - accuracy: 0.7700\n",
      "Epoch 3/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.4214 - accuracy: 0.8043\n",
      "Epoch 4/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.3986 - accuracy: 0.8229\n",
      "Epoch 5/350\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.3819 - accuracy: 0.8314\n",
      "Epoch 6/350\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.3649 - accuracy: 0.8514\n",
      "Epoch 7/350\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.3486 - accuracy: 0.8514\n",
      "Epoch 8/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.3342 - accuracy: 0.8629\n",
      "Epoch 9/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.3238 - accuracy: 0.8614\n",
      "Epoch 10/350\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.3123 - accuracy: 0.8629\n",
      "Epoch 11/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.3036 - accuracy: 0.8729\n",
      "Epoch 12/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.2946 - accuracy: 0.8714\n",
      "Epoch 13/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.2820 - accuracy: 0.8714\n",
      "Epoch 14/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.2706 - accuracy: 0.8857\n",
      "Epoch 15/350\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.2642 - accuracy: 0.8829\n",
      "Epoch 16/350\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.2558 - accuracy: 0.8871\n",
      "Epoch 17/350\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.2473 - accuracy: 0.8957\n",
      "Epoch 18/350\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.2418 - accuracy: 0.8886\n",
      "Epoch 19/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.2358 - accuracy: 0.8929\n",
      "Epoch 20/350\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.2345 - accuracy: 0.8957\n",
      "Epoch 21/350\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.2223 - accuracy: 0.9057\n",
      "Epoch 22/350\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.2118 - accuracy: 0.9114\n",
      "Epoch 23/350\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.2135 - accuracy: 0.9114\n",
      "Epoch 24/350\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.2120 - accuracy: 0.9086\n",
      "Epoch 25/350\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.1989 - accuracy: 0.9214\n",
      "Epoch 26/350\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.1933 - accuracy: 0.9114\n",
      "Epoch 27/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.1886 - accuracy: 0.9229\n",
      "Epoch 28/350\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.1941 - accuracy: 0.9171\n",
      "Epoch 29/350\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.1825 - accuracy: 0.9286\n",
      "Epoch 30/350\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.1746 - accuracy: 0.9343\n",
      "Epoch 31/350\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.1705 - accuracy: 0.9371\n",
      "Epoch 32/350\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.1685 - accuracy: 0.9314\n",
      "Epoch 33/350\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.1602 - accuracy: 0.9386\n",
      "Epoch 34/350\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.1627 - accuracy: 0.9371\n",
      "Epoch 35/350\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.1553 - accuracy: 0.9457\n",
      "Epoch 36/350\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.1550 - accuracy: 0.9457\n",
      "Epoch 37/350\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.1521 - accuracy: 0.9414\n",
      "Epoch 38/350\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.1441 - accuracy: 0.9486\n",
      "Epoch 39/350\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.1423 - accuracy: 0.9500\n",
      "Epoch 40/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.1409 - accuracy: 0.9543\n",
      "Epoch 41/350\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.1349 - accuracy: 0.9500\n",
      "Epoch 42/350\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.1377 - accuracy: 0.9443\n",
      "Epoch 43/350\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.1369 - accuracy: 0.9557\n",
      "Epoch 44/350\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.1326 - accuracy: 0.9514\n",
      "Epoch 45/350\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.1265 - accuracy: 0.9557\n",
      "Epoch 46/350\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.1261 - accuracy: 0.9557\n",
      "Epoch 47/350\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.1267 - accuracy: 0.9586\n",
      "Epoch 48/350\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.1228 - accuracy: 0.9543\n",
      "Epoch 49/350\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.1232 - accuracy: 0.9543\n",
      "Epoch 50/350\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.1138 - accuracy: 0.9614\n",
      "Epoch 51/350\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.1170 - accuracy: 0.9543\n",
      "Epoch 52/350\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.1087 - accuracy: 0.9600\n",
      "Epoch 53/350\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.1107 - accuracy: 0.9586\n",
      "Epoch 54/350\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.1080 - accuracy: 0.9629\n",
      "Epoch 55/350\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.1022 - accuracy: 0.9657\n",
      "Epoch 56/350\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.1099 - accuracy: 0.9629\n",
      "Epoch 57/350\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.1056 - accuracy: 0.9686\n",
      "Epoch 58/350\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.1011 - accuracy: 0.9614\n",
      "Epoch 59/350\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.0987 - accuracy: 0.9686\n",
      "Epoch 60/350\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.0969 - accuracy: 0.9700\n",
      "Epoch 61/350\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.0946 - accuracy: 0.9686\n",
      "Epoch 62/350\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.0944 - accuracy: 0.9743\n",
      "Epoch 63/350\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.0933 - accuracy: 0.9729\n",
      "Epoch 64/350\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.0905 - accuracy: 0.9714\n",
      "Epoch 65/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0960 - accuracy: 0.9686\n",
      "Epoch 66/350\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.0946 - accuracy: 0.9686\n",
      "Epoch 67/350\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.0925 - accuracy: 0.9671\n",
      "Epoch 68/350\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.0912 - accuracy: 0.9643\n",
      "Epoch 69/350\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0853 - accuracy: 0.9686\n",
      "Epoch 70/350\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.0889 - accuracy: 0.9629\n",
      "Epoch 71/350\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.0799 - accuracy: 0.9757\n",
      "Epoch 72/350\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0807 - accuracy: 0.9757\n",
      "Epoch 73/350\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.0756 - accuracy: 0.9757\n",
      "Epoch 74/350\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.0770 - accuracy: 0.9771\n",
      "Epoch 75/350\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.0756 - accuracy: 0.9771\n",
      "Epoch 76/350\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.0785 - accuracy: 0.9729\n",
      "Epoch 77/350\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0771 - accuracy: 0.9786\n",
      "Epoch 78/350\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.0766 - accuracy: 0.9743\n",
      "Epoch 79/350\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.0721 - accuracy: 0.9757\n",
      "Epoch 80/350\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.0708 - accuracy: 0.9771\n",
      "Epoch 81/350\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.0672 - accuracy: 0.9786\n",
      "Epoch 82/350\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.0720 - accuracy: 0.9743\n",
      "Epoch 83/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 3ms/step - loss: 0.0643 - accuracy: 0.9757\n",
      "Epoch 84/350\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.0634 - accuracy: 0.9843\n",
      "Epoch 85/350\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.0651 - accuracy: 0.9800\n",
      "Epoch 86/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0622 - accuracy: 0.9800\n",
      "Epoch 87/350\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.0633 - accuracy: 0.9786\n",
      "Epoch 88/350\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.0613 - accuracy: 0.9800\n",
      "Epoch 89/350\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.0639 - accuracy: 0.9800\n",
      "Epoch 90/350\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.0620 - accuracy: 0.9829\n",
      "Epoch 91/350\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.0588 - accuracy: 0.9829\n",
      "Epoch 92/350\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.0562 - accuracy: 0.9814\n",
      "Epoch 93/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0539 - accuracy: 0.9857\n",
      "Epoch 94/350\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.0549 - accuracy: 0.9829\n",
      "Epoch 95/350\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.0520 - accuracy: 0.9843\n",
      "Epoch 96/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0543 - accuracy: 0.9814\n",
      "Epoch 97/350\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.0594 - accuracy: 0.9786\n",
      "Epoch 98/350\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.0544 - accuracy: 0.9814\n",
      "Epoch 99/350\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.0487 - accuracy: 0.9871\n",
      "Epoch 100/350\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.0527 - accuracy: 0.9843\n",
      "Epoch 101/350\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.0466 - accuracy: 0.9857\n",
      "Epoch 102/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0483 - accuracy: 0.9857\n",
      "Epoch 103/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0508 - accuracy: 0.9829\n",
      "Epoch 104/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0452 - accuracy: 0.9857\n",
      "Epoch 105/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0460 - accuracy: 0.9843\n",
      "Epoch 106/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0399 - accuracy: 0.9900\n",
      "Epoch 107/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0464 - accuracy: 0.9843\n",
      "Epoch 108/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0417 - accuracy: 0.9900\n",
      "Epoch 109/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0424 - accuracy: 0.9886\n",
      "Epoch 110/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0407 - accuracy: 0.9900\n",
      "Epoch 111/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0446 - accuracy: 0.9857\n",
      "Epoch 112/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0377 - accuracy: 0.9871\n",
      "Epoch 113/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0377 - accuracy: 0.9871\n",
      "Epoch 114/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0369 - accuracy: 0.9957\n",
      "Epoch 115/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0371 - accuracy: 0.9886\n",
      "Epoch 116/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0363 - accuracy: 0.9914\n",
      "Epoch 117/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0341 - accuracy: 0.9900\n",
      "Epoch 118/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0339 - accuracy: 0.9900\n",
      "Epoch 119/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0329 - accuracy: 0.9929\n",
      "Epoch 120/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0315 - accuracy: 0.9900\n",
      "Epoch 121/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0343 - accuracy: 0.9886\n",
      "Epoch 122/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0324 - accuracy: 0.9886\n",
      "Epoch 123/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0331 - accuracy: 0.9929\n",
      "Epoch 124/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0362 - accuracy: 0.9900\n",
      "Epoch 125/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0335 - accuracy: 0.9900\n",
      "Epoch 126/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0319 - accuracy: 0.9886\n",
      "Epoch 127/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0354 - accuracy: 0.9914\n",
      "Epoch 128/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0320 - accuracy: 0.9886\n",
      "Epoch 129/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0420 - accuracy: 0.9871\n",
      "Epoch 130/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0355 - accuracy: 0.9886\n",
      "Epoch 131/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0343 - accuracy: 0.9914\n",
      "Epoch 132/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0456 - accuracy: 0.9814\n",
      "Epoch 133/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0380 - accuracy: 0.9886\n",
      "Epoch 134/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0297 - accuracy: 0.9943\n",
      "Epoch 135/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0318 - accuracy: 0.9900\n",
      "Epoch 136/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0265 - accuracy: 0.9957\n",
      "Epoch 137/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0248 - accuracy: 0.9929\n",
      "Epoch 138/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0268 - accuracy: 0.9943\n",
      "Epoch 139/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0259 - accuracy: 0.9943\n",
      "Epoch 140/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0272 - accuracy: 0.9914\n",
      "Epoch 141/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0250 - accuracy: 0.9929\n",
      "Epoch 142/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0211 - accuracy: 0.9971\n",
      "Epoch 143/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0351 - accuracy: 0.9829\n",
      "Epoch 144/350\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.0244 - accuracy: 0.9957\n",
      "Epoch 145/350\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.0258 - accuracy: 0.9943\n",
      "Epoch 146/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0214 - accuracy: 0.9986\n",
      "Epoch 147/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0214 - accuracy: 0.9986\n",
      "Epoch 148/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0217 - accuracy: 0.9986\n",
      "Epoch 149/350\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.0324 - accuracy: 0.9886\n",
      "Epoch 150/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0306 - accuracy: 0.9871\n",
      "Epoch 151/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0298 - accuracy: 0.9886\n",
      "Epoch 152/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0222 - accuracy: 0.9971\n",
      "Epoch 153/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0193 - accuracy: 0.9971\n",
      "Epoch 154/350\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.0176 - accuracy: 0.9986\n",
      "Epoch 155/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0203 - accuracy: 0.9971\n",
      "Epoch 156/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0169 - accuracy: 0.9971\n",
      "Epoch 157/350\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.0171 - accuracy: 0.9986\n",
      "Epoch 158/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0156 - accuracy: 0.9986\n",
      "Epoch 159/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0203 - accuracy: 0.9957\n",
      "Epoch 160/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0192 - accuracy: 0.9943\n",
      "Epoch 161/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0169 - accuracy: 0.9986\n",
      "Epoch 162/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0160 - accuracy: 0.9986\n",
      "Epoch 163/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0147 - accuracy: 0.9986\n",
      "Epoch 164/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0159 - accuracy: 0.9971\n",
      "Epoch 165/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0147 - accuracy: 0.9986\n",
      "Epoch 166/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0140 - accuracy: 0.9986\n",
      "Epoch 167/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0133 - accuracy: 0.9986\n",
      "Epoch 168/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0131 - accuracy: 0.9986\n",
      "Epoch 169/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0156 - accuracy: 0.9957\n",
      "Epoch 170/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0181 - accuracy: 0.9971\n",
      "Epoch 171/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0157 - accuracy: 0.9971\n",
      "Epoch 172/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0176 - accuracy: 0.9971\n",
      "Epoch 173/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0132 - accuracy: 0.9986\n",
      "Epoch 174/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0171 - accuracy: 0.9971\n",
      "Epoch 175/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0356 - accuracy: 0.9886\n",
      "Epoch 176/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0470 - accuracy: 0.9871\n",
      "Epoch 177/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0259 - accuracy: 0.9943\n",
      "Epoch 178/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0296 - accuracy: 0.9929\n",
      "Epoch 179/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0227 - accuracy: 0.9914\n",
      "Epoch 180/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0133 - accuracy: 0.9971\n",
      "Epoch 181/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0124 - accuracy: 0.9986\n",
      "Epoch 182/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0120 - accuracy: 0.9986\n",
      "Epoch 183/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0114 - accuracy: 1.0000\n",
      "Epoch 184/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0116 - accuracy: 0.9986\n",
      "Epoch 185/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0106 - accuracy: 0.9986\n",
      "Epoch 186/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0119 - accuracy: 1.0000\n",
      "Epoch 187/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0101 - accuracy: 1.0000\n",
      "Epoch 188/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0111 - accuracy: 0.9986\n",
      "Epoch 189/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0103 - accuracy: 0.9986\n",
      "Epoch 190/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0099 - accuracy: 1.0000\n",
      "Epoch 191/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0131 - accuracy: 0.9971\n",
      "Epoch 192/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0114 - accuracy: 0.9986\n",
      "Epoch 193/350\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.0100 - accuracy: 1.0000\n",
      "Epoch 194/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0091 - accuracy: 1.0000\n",
      "Epoch 195/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0102 - accuracy: 0.9986\n",
      "Epoch 196/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0112 - accuracy: 0.9986\n",
      "Epoch 197/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0087 - accuracy: 1.0000\n",
      "Epoch 198/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0098 - accuracy: 0.9986\n",
      "Epoch 199/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0110 - accuracy: 0.9986\n",
      "Epoch 200/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0124 - accuracy: 0.9971\n",
      "Epoch 201/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0090 - accuracy: 0.9986\n",
      "Epoch 202/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0097 - accuracy: 0.9986\n",
      "Epoch 203/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0086 - accuracy: 1.0000\n",
      "Epoch 204/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0081 - accuracy: 1.0000\n",
      "Epoch 205/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0082 - accuracy: 1.0000\n",
      "Epoch 206/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0095 - accuracy: 1.0000\n",
      "Epoch 207/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0076 - accuracy: 1.0000\n",
      "Epoch 208/350\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.0100 - accuracy: 1.0000\n",
      "Epoch 209/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0085 - accuracy: 0.9986\n",
      "Epoch 210/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0082 - accuracy: 1.0000\n",
      "Epoch 211/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0085 - accuracy: 1.0000\n",
      "Epoch 212/350\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.0083 - accuracy: 0.9986\n",
      "Epoch 213/350\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0081 - accuracy: 0.9986\n",
      "Epoch 214/350\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0080 - accuracy: 0.9986\n",
      "Epoch 215/350\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0076 - accuracy: 1.0000\n",
      "Epoch 216/350\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.0065 - accuracy: 1.0000\n",
      "Epoch 217/350\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.0079 - accuracy: 0.9986\n",
      "Epoch 218/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0076 - accuracy: 1.0000\n",
      "Epoch 219/350\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.0077 - accuracy: 1.0000\n",
      "Epoch 220/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0091 - accuracy: 1.0000\n",
      "Epoch 221/350\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.0115 - accuracy: 0.9986\n",
      "Epoch 222/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0078 - accuracy: 0.9986\n",
      "Epoch 223/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0067 - accuracy: 1.0000\n",
      "Epoch 224/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0058 - accuracy: 1.0000\n",
      "Epoch 225/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0060 - accuracy: 1.0000\n",
      "Epoch 226/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0071 - accuracy: 0.9986\n",
      "Epoch 227/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0058 - accuracy: 1.0000\n",
      "Epoch 228/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0055 - accuracy: 1.0000\n",
      "Epoch 229/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0064 - accuracy: 1.0000\n",
      "Epoch 230/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0080 - accuracy: 0.9986\n",
      "Epoch 231/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0072 - accuracy: 1.0000\n",
      "Epoch 232/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0061 - accuracy: 1.0000\n",
      "Epoch 233/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0055 - accuracy: 1.0000\n",
      "Epoch 234/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0062 - accuracy: 1.0000\n",
      "Epoch 235/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0066 - accuracy: 1.0000\n",
      "Epoch 236/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0061 - accuracy: 0.9986\n",
      "Epoch 237/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0054 - accuracy: 1.0000\n",
      "Epoch 238/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0052 - accuracy: 1.0000\n",
      "Epoch 239/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0055 - accuracy: 1.0000\n",
      "Epoch 240/350\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.0048 - accuracy: 1.0000\n",
      "Epoch 241/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0045 - accuracy: 1.0000\n",
      "Epoch 242/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0044 - accuracy: 1.0000\n",
      "Epoch 243/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0045 - accuracy: 1.0000\n",
      "Epoch 244/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0042 - accuracy: 1.0000\n",
      "Epoch 245/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0044 - accuracy: 1.0000\n",
      "Epoch 246/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0047 - accuracy: 1.0000\n",
      "Epoch 247/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0041 - accuracy: 1.0000\n",
      "Epoch 248/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0040 - accuracy: 1.0000\n",
      "Epoch 249/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0044 - accuracy: 1.0000\n",
      "Epoch 250/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0046 - accuracy: 1.0000\n",
      "Epoch 251/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0043 - accuracy: 1.0000\n",
      "Epoch 252/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0040 - accuracy: 1.0000\n",
      "Epoch 253/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0061 - accuracy: 1.0000\n",
      "Epoch 254/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0047 - accuracy: 1.0000\n",
      "Epoch 255/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0035 - accuracy: 1.0000\n",
      "Epoch 256/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0041 - accuracy: 1.0000\n",
      "Epoch 257/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0052 - accuracy: 1.0000\n",
      "Epoch 258/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0039 - accuracy: 1.0000\n",
      "Epoch 259/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0036 - accuracy: 1.0000\n",
      "Epoch 260/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0045 - accuracy: 1.0000\n",
      "Epoch 261/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0061 - accuracy: 1.0000\n",
      "Epoch 262/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0046 - accuracy: 1.0000\n",
      "Epoch 263/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0036 - accuracy: 1.0000\n",
      "Epoch 264/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 265/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0044 - accuracy: 1.0000\n",
      "Epoch 266/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 267/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 268/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 269/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 270/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 271/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 272/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 273/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 274/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 275/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 276/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 277/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 278/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 279/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 280/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 281/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 282/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0033 - accuracy: 1.0000\n",
      "Epoch 283/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 284/350\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 285/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 286/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 287/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 288/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0033 - accuracy: 1.0000\n",
      "Epoch 289/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 290/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 291/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 292/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 293/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0043 - accuracy: 1.0000\n",
      "Epoch 294/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0093 - accuracy: 0.9957\n",
      "Epoch 295/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0172 - accuracy: 0.9929\n",
      "Epoch 296/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0706 - accuracy: 0.9771\n",
      "Epoch 297/350\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.1675 - accuracy: 0.9643\n",
      "Epoch 298/350\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.1311 - accuracy: 0.9700\n",
      "Epoch 299/350\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.0541 - accuracy: 0.9757\n",
      "Epoch 300/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0184 - accuracy: 0.9943\n",
      "Epoch 301/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0065 - accuracy: 0.9986\n",
      "Epoch 302/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0049 - accuracy: 1.0000\n",
      "Epoch 303/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0042 - accuracy: 1.0000\n",
      "Epoch 304/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0035 - accuracy: 1.0000\n",
      "Epoch 305/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 306/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 307/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 308/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 309/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 310/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 311/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 312/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 313/350\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 314/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 315/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 316/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 317/350\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 318/350\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 319/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 320/350\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 321/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 322/350\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 323/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 324/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 325/350\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 326/350\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 327/350\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 328/350\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 329/350\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 330/350\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 331/350\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 332/350\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 333/350\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 334/350\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 335/350\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 336/350\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 337/350\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 338/350\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 339/350\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 340/350\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 341/350\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 342/350\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 343/350\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 344/350\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 345/350\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 346/350\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 347/350\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 348/350\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 349/350\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 350/350\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.0016 - accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_9004\\2242147268.py:121: RuntimeWarning: divide by zero encountered in log2\n",
      "  entropy = -np.sum(np.log2(image / 256) * (image / 256), axis=(0, 1))\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_9004\\2242147268.py:121: RuntimeWarning: invalid value encountered in multiply\n",
      "  entropy = -np.sum(np.log2(image / 256) * (image / 256), axis=(0, 1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "# CODE implementing ANN for binary classification (with one hidden layer)\n",
    "\n",
    "# Importing all the required libraries\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow import keras\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n",
    "# Loading the training data\n",
    "train_raveling = os.listdir('train/Raveling')\n",
    "train_non_raveling = os.listdir('train/Non_raveling')\n",
    "train_images = []\n",
    "train_labels = []\n",
    "\n",
    "# preprocess the training data\n",
    "for img in train_raveling:\n",
    "    image = cv2.imread('train/Raveling/' + img)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    h, w, _ = image.shape\n",
    "    total_pixels = h * w\n",
    "   \n",
    "    # Calculating features as given in the paper \n",
    "\n",
    "    mean = np.mean(image, axis=(0, 1))\n",
    "    std = np.std(image, axis=(0, 1))\n",
    "    skewness = np.mean((image - mean) ** 3, axis=(0, 1)) / (std ** 3)\n",
    "    kurtosis = np.mean((image - mean) ** 4, axis=(0, 1)) / (std ** 4) \n",
    "    entropy = -np.sum(np.log2(image / 256) * (image / 256), axis=(0, 1))\n",
    "    rng = np.max(image, axis=(0, 1)) - np.min(image, axis=(0, 1))\n",
    "    first_order_histogram = []\n",
    "    total_pixels = image.shape[0] * image.shape[1]\n",
    "    first_order_histogram = []\n",
    "    for c in range(3):\n",
    "        n_c = np.sum(image[:, :, c])\n",
    "        Pc_I = n_c / total_pixels\n",
    "        first_order_histogram.append(Pc_I)\n",
    "\n",
    "    mean_mod = mean * first_order_histogram\n",
    "    std_mod = std * first_order_histogram\n",
    "    skewness_mod = skewness * first_order_histogram\n",
    "    kurtosis_mod = kurtosis * first_order_histogram\n",
    "    entropy_mod = entropy * first_order_histogram\n",
    "    rng_mod = rng * first_order_histogram\n",
    "    features = np.concatenate([mean_mod, std_mod, skewness_mod, kurtosis_mod, entropy_mod, rng_mod])\n",
    "    train_images.append(features)\n",
    "    train_labels.append(1)  #label raveling as 1\n",
    "\n",
    "for img in train_non_raveling:\n",
    "    image = cv2.imread('train/Non_raveling/' + img)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    h, w, _ = image.shape\n",
    "    total_pixels = h * w\n",
    "\n",
    "    # Calculating features as given in the paper \n",
    "\n",
    "    mean = np.mean(image, axis=(0, 1))\n",
    "    std = np.std(image, axis=(0, 1))\n",
    "    skewness = np.mean((image - mean) ** 3, axis=(0, 1)) / (std ** 3)\n",
    "    kurtosis = np.mean((image - mean) ** 4, axis=(0, 1)) / (std ** 4) \n",
    "    entropy = -np.sum(np.log2(image / 256) * (image / 256), axis=(0, 1))\n",
    "    rng = np.max(image, axis=(0, 1)) - np.min(image, axis=(0, 1))\n",
    "    first_order_histogram = []\n",
    "    total_pixels = image.shape[0] * image.shape[1]\n",
    "    first_order_histogram = []\n",
    "    for c in range(3):\n",
    "        n_c = np.sum(image[:, :, c])\n",
    "        Pc_I = n_c / total_pixels\n",
    "        first_order_histogram.append(Pc_I)\n",
    "    mean_mod = mean * first_order_histogram\n",
    "    std_mod = std * first_order_histogram\n",
    "    skewness_mod = skewness * first_order_histogram\n",
    "    kurtosis_mod = kurtosis * first_order_histogram\n",
    "    entropy_mod = entropy * first_order_histogram\n",
    "    rng_mod = rng * first_order_histogram\n",
    "    features = np.concatenate([mean_mod, std_mod, skewness_mod, kurtosis_mod, entropy_mod, rng_mod])\n",
    "    train_images.append(features)\n",
    "    train_labels.append(0)  #label non-raveling as 0\n",
    "train_images = np.array(train_images)\n",
    "train_labels = np.array(train_labels) \n",
    "\n",
    "# removing NaN error\n",
    "imp = SimpleImputer(strategy='mean')\n",
    "train_images = imp.fit_transform(train_images)\n",
    "scaler = StandardScaler()\n",
    "train_images = scaler.fit_transform(train_images)\n",
    "\n",
    "\n",
    "# Building a shallow neural network with a single hidden layer (128 units)\n",
    "\n",
    "# model = keras.Sequential([keras.layers.InputLayer(input_shape=(train_images.shape[1],)),\n",
    "#     keras.layers.Dense(128, activation='relu'),\n",
    "#     keras.layers.Dense(1, activation='sigmoid')])   0.9666 score\n",
    "\n",
    "model = keras.Sequential([keras.layers.InputLayer(input_shape=(train_images.shape[1],)),\n",
    "    keras.layers.Dense(128, activation='relu'),keras.layers.Dense(32, activation='relu'),\n",
    "    keras.layers.Dense(1, activation='sigmoid')])\n",
    "\n",
    "# Compile the model with binary cross-entropy loss, Adam optimizer, and accuracy metric\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Fit the model to the training data\n",
    "model.fit(train_images, train_labels, epochs=350, batch_size=32)\n",
    "\n",
    "\n",
    "test_images=[]\n",
    "filenames=[]\n",
    "\n",
    "# Loading  and preprocessing the test data\n",
    "\n",
    "for i in range(1, 301):\n",
    "    image = cv2.imread('test/' + str(i) + '.jpg')\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    h, w, _ = image.shape\n",
    "    total_pixels = h * w\n",
    "    mean = np.mean(image, axis=(0, 1))\n",
    "    std = np.std(image, axis=(0, 1))\n",
    "    skewness = np.mean((image - mean) ** 3, axis=(0, 1)) / (std ** 3)\n",
    "    kurtosis = np.mean((image - mean) ** 4, axis=(0, 1)) / (std ** 4) \n",
    "    entropy = -np.sum(np.log2(image / 256) * (image / 256), axis=(0, 1))\n",
    "    rng = np.max(image, axis=(0, 1)) - np.min(image, axis=(0, 1))\n",
    "    first_order_histogram = []\n",
    "    total_pixels = image.shape[0] * image.shape[1]\n",
    "    first_order_histogram = []\n",
    "    for c in range(3):\n",
    "        n_c = np.sum(image[:, :, c])\n",
    "        Pc_I = n_c / total_pixels\n",
    "        first_order_histogram.append(Pc_I)\n",
    "\n",
    "    mean_mod = mean * first_order_histogram\n",
    "    std_mod = std * first_order_histogram\n",
    "    skewness_mod = skewness * first_order_histogram\n",
    "    kurtosis_mod = kurtosis * first_order_histogram\n",
    "    entropy_mod = entropy * first_order_histogram\n",
    "    rng_mod = rng * first_order_histogram\n",
    "    features = np.concatenate([mean_mod, std_mod, skewness_mod, kurtosis_mod, entropy_mod, rng_mod])\n",
    "    test_images.append(features)\n",
    "    filenames.append(str(i) + '.jpg')\n",
    "\n",
    "test_images = np.array(test_images)\n",
    "imp = SimpleImputer(strategy='mean')\n",
    "test_images = imp.fit_transform(test_images)\n",
    "test_images = scaler.transform(test_images)\n",
    "predictions=[]\n",
    "# Predicting the test labels\n",
    "predictions = model.predict(test_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e452fb8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 2ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Accuracy of model on training data 1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of model on training data\",model.evaluate(train_images,train_labels)[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "549f7278",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "test_labels=[]\n",
    "for i in range(0,len(predictions)):\n",
    "    # Convert predictions above 0.5 to non-raveling and rest to raveling class     \n",
    "    if predictions[i]<0.5:\n",
    "        test_labels.append(\"Non_raveling\")\n",
    "    else:\n",
    "        test_labels.append(\"Raveling\")\n",
    "#Storing filename and labels in dataframe     \n",
    "df = pd.DataFrame({'filename': filenames, 'class': test_labels})\n",
    "#Changing dataframe to csv file\n",
    "df.to_csv('hzpredictionsAnn22103025Final.csv', index=False)    \n",
    "######################################END OF CODE#######################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b80012",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4212adfb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12edb95b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dab8666",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab17a317",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0d216846",
   "metadata": {},
   "source": [
    "SOLUTION: LOGISTIC REGRESSION MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bd5b7c74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_9004\\1123209733.py:26: RuntimeWarning: divide by zero encountered in log2\n",
      "  entropy = -np.sum(np.log2(image / 256) * (image / 256), axis=(0, 1))\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_9004\\1123209733.py:26: RuntimeWarning: invalid value encountered in multiply\n",
      "  entropy = -np.sum(np.log2(image / 256) * (image / 256), axis=(0, 1))\n",
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_9004\\1123209733.py:99: RuntimeWarning: divide by zero encountered in log2\n",
      "  entropy = -np.sum(np.log2(image / 256) * (image / 256), axis=(0, 1))\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_9004\\1123209733.py:99: RuntimeWarning: invalid value encountered in multiply\n",
      "  entropy = -np.sum(np.log2(image / 256) * (image / 256), axis=(0, 1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data: 0.8014285714285714\n"
     ]
    }
   ],
   "source": [
    "# CODE implementing LOGISTIC REGRESSION for binary classification\n",
    "\n",
    "# Importing all the required libraries\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# Load and preprocess the training data\n",
    "train_raveling = os.listdir('train/Raveling')\n",
    "train_non_raveling = os.listdir('train/Non_raveling')\n",
    "train_images = []\n",
    "train_labels = []\n",
    "\n",
    "for img in train_raveling:\n",
    "    image = cv2.imread('train/Raveling/' + img)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    h, w, _ = image.shape\n",
    "    total_pixels = h * w\n",
    "    mean = np.mean(image, axis=(0, 1))\n",
    "    std = np.std(image, axis=(0, 1))\n",
    "    skewness = np.mean((image - mean) ** 3, axis=(0, 1)) / (std ** 3)\n",
    "    kurtosis = np.mean((image - mean) ** 4, axis=(0, 1)) / (std ** 4) \n",
    "    entropy = -np.sum(np.log2(image / 256) * (image / 256), axis=(0, 1))\n",
    "    rng = np.max(image, axis=(0, 1)) - np.min(image, axis=(0, 1))\n",
    "    first_order_histogram = []\n",
    "    total_pixels = image.shape[0] * image.shape[1]\n",
    "    # Calculating features as given in the paper \n",
    "    \n",
    "    first_order_histogram = []\n",
    "    for c in range(3):\n",
    "        n_c = np.sum(image[:, :, c])\n",
    "        Pc_I = n_c / total_pixels\n",
    "        first_order_histogram.append(Pc_I)\n",
    "\n",
    "    mean_mod = mean * first_order_histogram\n",
    "    std_mod = std * first_order_histogram\n",
    "    skewness_mod = skewness * first_order_histogram\n",
    "    kurtosis_mod = kurtosis * first_order_histogram\n",
    "    entropy_mod = entropy * first_order_histogram\n",
    "    rng_mod = rng * first_order_histogram\n",
    "    features = np.concatenate([mean_mod, std_mod, skewness_mod, kurtosis_mod, entropy_mod, rng_mod])\n",
    "    train_images.append(features)\n",
    "    train_labels.append(1)  #label raveling as 1\n",
    "\n",
    "for img in train_non_raveling:\n",
    "    image = cv2.imread('train/Non_raveling/' + img)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    h, w, _ = image.shape\n",
    "    total_pixels = h * w\n",
    "    mean = np.mean(image, axis=(0, 1))\n",
    "    std = np.std(image, axis=(0, 1))\n",
    "    skewness = np.mean((image - mean) ** 3, axis=(0, 1)) / (std ** 3)\n",
    "    kurtosis = np.mean((image - mean) ** 4, axis=(0, 1)) / (std ** 4) \n",
    "    entropy = -np.sum(np.log2(image / 256) * (image / 256), axis=(0, 1))\n",
    "    rng = np.max(image, axis=(0, 1)) - np.min(image, axis=(0, 1))\n",
    "    first_order_histogram = []\n",
    "    total_pixels = image.shape[0] * image.shape[1]\n",
    "    first_order_histogram = []\n",
    "    for c in range(3):\n",
    "        n_c = np.sum(image[:, :, c])\n",
    "        Pc_I = n_c / total_pixels\n",
    "        first_order_histogram.append(Pc_I)\n",
    "\n",
    "    mean_mod = mean * first_order_histogram\n",
    "    std_mod = std * first_order_histogram\n",
    "    skewness_mod = skewness * first_order_histogram\n",
    "    kurtosis_mod = kurtosis * first_order_histogram\n",
    "    entropy_mod = entropy * first_order_histogram\n",
    "    rng_mod = rng * first_order_histogram\n",
    "    features = np.concatenate([mean_mod, std_mod, skewness_mod, kurtosis_mod, entropy_mod, rng_mod])\n",
    "    train_images.append(features)\n",
    "    train_labels.append(0)  #label non-raveling as 0\n",
    "train_images = np.array(train_images)\n",
    "train_labels = np.array(train_labels) \n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# removing NaN error\n",
    "imp = SimpleImputer(strategy='mean')\n",
    "train_images = imp.fit_transform(train_images)\n",
    "# Train the Logistic Regression model\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(train_images, train_labels)\n",
    "#reading test images:\n",
    "test_images=[]\n",
    "filenames=[]\n",
    "for i in range(1, 301):\n",
    "    image = cv2.imread('test/' + str(i) + '.jpg')\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    h, w, _ = image.shape\n",
    "    total_pixels = h * w\n",
    "    mean = np.mean(image, axis=(0, 1))\n",
    "    std = np.std(image, axis=(0, 1))\n",
    "    skewness = np.mean((image - mean) ** 3, axis=(0, 1)) / (std ** 3)\n",
    "    kurtosis = np.mean((image - mean) ** 4, axis=(0, 1)) / (std ** 4) \n",
    "    entropy = -np.sum(np.log2(image / 256) * (image / 256), axis=(0, 1))\n",
    "    rng = np.max(image, axis=(0, 1)) - np.min(image, axis=(0, 1))\n",
    "    first_order_histogram = []\n",
    "    total_pixels = image.shape[0] * image.shape[1]\n",
    "    first_order_histogram = []\n",
    "    for c in range(3):\n",
    "        n_c = np.sum(image[:, :, c])\n",
    "        Pc_I = n_c / total_pixels\n",
    "        first_order_histogram.append(Pc_I)\n",
    "\n",
    "    mean_mod = mean * first_order_histogram\n",
    "    std_mod = std * first_order_histogram\n",
    "    skewness_mod = skewness * first_order_histogram\n",
    "    kurtosis_mod = kurtosis * first_order_histogram\n",
    "    entropy_mod = entropy * first_order_histogram\n",
    "    rng_mod = rng * first_order_histogram\n",
    "    features = np.concatenate([mean_mod, std_mod, skewness_mod, kurtosis_mod, entropy_mod, rng_mod])\n",
    "    test_images.append(features)\n",
    "    filenames.append(str(i) + '.jpg')\n",
    "test_labels2=[]\n",
    "test_images = np.array(test_images)\n",
    "test_images=imp.fit_transform(test_images)\n",
    "#predicting class of test image using our developed model:\n",
    "test_labels = model.predict(test_images)\n",
    "for i in range(len(test_labels)):\n",
    "    if test_labels[i]==0:\n",
    "        test_labels2.append(\"Non_raveling\")\n",
    "# #         test_labels2[i]=\"Non_raveling\"\n",
    "    elif test_labels[i]==1:\n",
    "        test_labels2.append(\"Raveling\")\n",
    "#Checking order of accuracy of train data:\n",
    "accuracy = model.score(train_images, train_labels)\n",
    "print(\"Accuracy on training data:\", accuracy)\n",
    "df = pd.DataFrame({'filename': filenames, 'class': test_labels2})\n",
    "#Changing dataframe to csv file\n",
    "df.to_csv('predictionsLR1.csv', index=False)\n",
    "\n",
    "######################################END OF CODE#######################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c6b2b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
